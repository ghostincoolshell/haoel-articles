<html><body><p>最近在学习一些数据挖掘的算法，看到了这个算法，也许这个算法对你来说很简单，但对我来说，我是一个初学者，我在网上翻看了很多资料，发现中文社区没有把这个问题讲得很全面很清楚的文章，所以，把我的学习笔记记录下来，分享给大家。</p>
<p>在数据挖掘中， <strong><em>k</em>-Means 算法</strong>是一种 <a href="http://en.wikipedia.org/wiki/Cluster_analysis" title="Cluster analysis">cluster analysis</a> 的算法，其主要是来计算数据聚集的算法，主要通过不断地取离种子点最近均值的算法。</p>
<h4>问题</h4>
<p>K-Means算法主要解决的问题如下图所示。我们可以看到，在图的左边有一些点，我们用肉眼可以看出来有四个点群，但是我们怎么通过计算机程序找出这几个点群来呢？于是就出现了我们的K-Means算法（<a href="http://en.wikipedia.org/wiki/K-means_clustering" target="_blank" title="K-means Clustering 算法">Wikipedia链接</a>）</p>
<figure class="wp-caption aligncenter" id="attachment_7780" style="width: 600px;"><img alt="" class="size-full wp-image-7780" height="300" src="../wp-content/uploads/2012/06/K-Means.gif" title="K-Means 要解决的问题" width="600"/><figcaption class="wp-caption-text" id="caption-attachment-7780">K-Means 要解决的问题</figcaption></figure>
<h4>算法概要</h4>
<p>这个算法其实很简单，如下图所示：</p>
<p><span id="more-7779"></span></p>
<figure class="wp-caption aligncenter" id="attachment_7781" style="width: 504px;"><img alt="K-Means 算法概要" class="size-full wp-image-7781" height="370" src="../wp-content/uploads/2012/06/K-Means.jpg" title="K-Means 算法概要" width="504"/><figcaption class="wp-caption-text" id="caption-attachment-7781">K-Means 算法概要</figcaption></figure>
<p>从上图中，我们可以看到，<strong>A, B, C, D, E 是五个在图中点。而灰色的点是我们的种子点，也就是我们用来找点群的点</strong>。有两个种子点，所以K=2。</p>
<p>然后，K-Means的算法如下：</p>
<ol>
<li>随机在图中取K（这里K=2）个种子点。</li>
<li>然后对图中的所有点求到这K个种子点的距离，假如点Pi离种子点Si最近，那么Pi属于Si点群。（上图中，我们可以看到A,B属于上面的种子点，C,D,E属于下面中部的种子点）</li>
<li>接下来，我们要移动种子点到属于他的“点群”的中心。（见图上的第三步）</li>
<li>然后重复第2）和第3）步，直到，种子点没有移动（我们可以看到图中的第四步上面的种子点聚合了A,B,C，下面的种子点聚合了D，E）。</li>
</ol>
<p>这个算法很简单，但是有些细节我要提一下，求距离的公式我不说了，大家有初中毕业水平的人都应该知道怎么算的。我重点想说一下“求点群中心的算法”</p>
<h4>求点群中心的算法</h4>
<p>一般来说，求点群中心点的算法你可以很简的使用各个点的X/Y坐标的平均值。不过，我这里想告诉大家另三个求中心点的的公式：</p>
<p><strong>1）Minkowski Distance 公式 ——</strong> λ 可以随意取值，可以是负数，也可以是正数，或是无穷大。</p>
<p><img alt="" class="aligncenter size-full wp-image-7787" height="51" src="../wp-content/uploads/2012/06/MinkowskiDistance_clip_image102.gif" title="Minkowski Distance 公式" width="131"/></p>
<p><strong>2）Euclidean Distance 公式 </strong>—— 也就是第一个公式 λ=2 的情况</p>
<p><img alt="" class="aligncenter size-full wp-image-7784" height="51" src="../wp-content/uploads/2012/06/EuclideanDistance_clip_image002.gif" title="Euclidean Distance 公式" width="137"/></p>
<p><strong>3）CityBlock Distance 公式 </strong>—— 也就是第一个公式 λ=1 的情况</p>
<p><img alt="" class="aligncenter size-full wp-image-7782" height="45" src="../wp-content/uploads/2012/06/CityBlockDistance_clip_image002.gif" title="CityBlock Distance 公式" width="111"/></p>
<p>这三个公式的求中心点有一些不一样的地方，我们看下图（对于第一个 λ 在 0-1之间）。</p>
<p style="text-align: center;"><img alt="" height="180" src="../wp-content/uploads/2012/06/Minkowski-Mean.jpg" title="Minkowski Mean" width="180"/>   <img alt="" height="180" src="../wp-content/uploads/2012/06/Euclidean-distance.jpg" title="Euclidean distance" width="180"/>  <img alt="" height="180" src="../wp-content/uploads/2012/06/Manhattan-distance.jpg" title="Manhattan distance" width="180"/></p>
<p style="text-align: center;"><strong>（1）Minkowski Distance     （2）<strong>Euclidean Distance    （3） <strong>CityBlock Distance</strong></strong></strong></p>
<p style="text-align: left;">上面这几个图的大意是他们是怎么个逼近中心的，第一个图以星形的方式，第二个图以同心圆的方式，第三个图以菱形的方式。</p>
<h4 style="text-align: left;">K-Means的演示</h4>
<p style="text-align: left;">如果你以”<a href="https://www.google.com/search?hl=zh-CN&amp;q=K+Means+Demo" target="_blank">K Means Demo</a>“为关键字到Google里查你可以查到很多演示。这里推荐一个演示</p>
<p style="text-align: center;"><a href="http://home.dei.polimi.it/matteucc/Clustering/tutorial_html/AppletKM.html">http://home.dei.polimi.it/matteucc/Clustering/tutorial_html/AppletKM.html</a></p>
<p style="text-align: left;">操作是，鼠标左键是初始化点，右键初始化“种子点”，然后勾选“Show History”可以看到一步一步的迭代。</p>
<p style="text-align: left;">注：这个演示的链接也有一个不错的 <a href="http://home.dei.polimi.it/matteucc/Clustering/tutorial_html/index.html" target="_blank">K Means Tutorial</a> 。</p>
<h4 style="text-align: left;">K-Means ++ 算法</h4>
<p>K-Means主要有两个最重大的缺陷——都和初始值有关：</p>
<ul>
<li> K 是事先给定的，这个 K 值的选定是非常难以估计的。很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适。（ <a href="http://en.wikipedia.org/wiki/Multispectral_pattern_recognition" target="_blank">ISODATA 算法</a>通过类的自动合并和分裂，得到较为合理的类型数目 K）</li>
</ul>
<ul>
<li>K-Means算法需要用初始随机种子点来搞，这个随机种子点太重要，不同的随机种子点会有得到完全不同的结果。（<a href="http://en.wikipedia.org/wiki/K-means%2B%2B" target="_blank">K-Means++算法</a>可以用来解决这个问题，其可以有效地选择初始点）</li>
</ul>
<p>我在这里重点说一下 K-Means++算法步骤：</p>
<ol>
<li>先从我们的数据库随机挑个随机点当“种子点”。</li>
<li>对于每个点，我们都计算其和最近的一个“种子点”的距离D(<var>x</var>)并保存在一个数组里，然后把这些距离加起来得到Sum(D(<var>x</var>))。</li>
<li>然后，再取一个随机值，用权重的方式来取计算下一个“种子点”。这个算法的实现是，先取一个能落在Sum(D(<var>x</var>))中的随机值Random，然后用Random -= D(<var>x</var>)，直到其&lt;=0，此时的点就是下一个“种子点”。</li>
<li>重复第（2）和第（3）步直到所有的K个种子点都被选出来。</li>
<li>进行K-Means算法。</li>
</ol>
<p>相关的代码你可以在这里找到“<a href="http://rosettacode.org/wiki/K-means%2B%2B_clustering" target="_blank">implement the K-means++ algorithm</a>”(墙) 另，<a href="http://commons.apache.org/math/api-2.1/index.html?org/apache/commons/math/stat/clustering/KMeansPlusPlusClusterer.html" rel="nofollow" target="_blank">Apache 的通用数据学库也实现了这一算法</a></p>
<h4>K-Means 算法应用</h4>
<p>看到这里，你会说，K-Means算法看来很简单，而且好像就是在玩坐标点，没什么真实用处。而且，这个算法缺陷很多，还不如人工呢。是的，前面的例子只是玩二维坐标点，的确没什么意思。但是你想一下下面的几个问题：</p>
<p style="padding-left: 30px;">1）如果不是二维的，是多维的，如5维的，那么，就只能用计算机来计算了。</p>
<p style="padding-left: 30px;">2）二维坐标点的X, Y 坐标，其实是一种向量，是一种数学抽象。现实世界中很多属性是可以抽象成向量的，比如，我们的年龄，我们的喜好，我们的商品，等等，能抽象成向量的目的就是可以让计算机知道某两个属性间的距离。如：我们认为，18岁的人离24岁的人的距离要比离12岁的距离要近，鞋子这个商品离衣服这个商品的距离要比电脑要近，等等。</p>
<p><strong>只要能把现实世界的物体的属性抽象成向量，就可以用K-Means算法来归类了</strong>。</p>
<p>在 《<a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/20/k-means.html" id="ctl01_lnkTitle">k均值聚类(K-means)</a>》 这篇文章中举了一个很不错的应用例子，作者用亚洲15支足球队的2005年到1010年的战绩做了一个向量表，然后用K-Means把球队归类，得出了下面的结果，呵呵。</p>
<ul>
<li>亚洲一流：日本，韩国，伊朗，沙特</li>
<li>亚洲二流：乌兹别克斯坦，巴林，朝鲜</li>
<li>亚洲三流：中国，伊拉克，卡塔尔，阿联酋，泰国，越南，阿曼，印尼</li>
</ul>
<p>其实，这样的业务例子还有很多，比如，分析一个公司的客户分类，这样可以对不同的客户使用不同的商业策略，或是电子商务中分析商品相似度，归类商品，从而可以使用一些不同的销售策略，等等。</p>
<p>最后给一个挺好的算法的幻灯片：<a href="http://www.cs.cmu.edu/~guestrin/Class/10701-S07/Slides/clustering.pdf">http://www.cs.cmu.edu/~guestrin/Class/10701-S07/Slides/clustering.pdf</a></p>
<p>（全文完）<!--



<p align="center"><a href= target=_blank><img decoding="async" src=""></a></p>





<p align="center"><img decoding="async" src="https://coolshell.cn/wp-content/uploads/2020/03/coolshell.weixin.jpg"> <img decoding="async" loading="lazy" src="https://coolshell.cn/wp-content/uploads/2020/03/coolshell.mini_.jpg" width="300" height="300"> <br />关注CoolShell微信公众账号和微信小程序</p>

 

--></p>
<div style="margin-top: 15px; font-size: 16px; color: #cc0000;">
<p align="center"><strong>（转载本站文章请注明作者和出处 <a href="https://coolshell.cn/">酷 壳 – CoolShell</a> ，请勿用于任何商业用途）</strong></p>
</div>
<div class="wp_rp_wrap wp_rp_vertical_m" id="wp_rp_first"><div class="wp_rp_content"><h3 class="related_post_title">相关文章</h3><ul class="related_post wp_rp"><li><a class="wp_rp_thumbnail" href="https://coolshell.cn/articles/8052.html"><img alt="K Nearest Neighbor 算法" height="150" src="../wp-content/uploads/2012/08/220px-KnnClassification.svg_-150x150.png" width="150"/></a><a class="wp_rp_title" href="https://coolshell.cn/articles/8052.html">K Nearest Neighbor 算法</a></li><li><a class="wp_rp_thumbnail" href="https://coolshell.cn/articles/17225.html"><img alt="Cuckoo Filter：设计与实现" height="150" src="../wp-content/uploads/2015/08/cuckoo-150x150.jpg" width="150"/></a><a class="wp_rp_title" href="https://coolshell.cn/articles/17225.html">Cuckoo Filter：设计与实现</a></li><li><a class="wp_rp_thumbnail" href="https://coolshell.cn/articles/12052.html"><img alt="Leetcode 编程训练" height="150" src="https://coolshell.cn/wp-content/plugins/wordpress-23-related-posts-plugin/static/thumbs/29.jpg" width="150"/></a><a class="wp_rp_title" href="https://coolshell.cn/articles/12052.html">Leetcode 编程训练</a></li><li><a class="wp_rp_thumbnail" href="https://coolshell.cn/articles/11847.html"><img alt="谜题的答案和活动的心得体会" height="150" src="../wp-content/uploads/2014/08/puzzle-150x150.png" width="150"/></a><a class="wp_rp_title" href="https://coolshell.cn/articles/11847.html">谜题的答案和活动的心得体会</a></li><li><a class="wp_rp_thumbnail" href="https://coolshell.cn/articles/11832.html"><img alt="【活动】解迷题送礼物" height="150" src="../wp-content/uploads/2014/08/538efefbgw1eiz9cvx78fj20rm0fmdi8-150x150.jpg" width="150"/></a><a class="wp_rp_title" href="https://coolshell.cn/articles/11832.html">【活动】解迷题送礼物</a></li><li><a class="wp_rp_thumbnail" href="https://coolshell.cn/articles/10590.html"><img alt="二维码的生成细节和原理" height="150" src="../wp-content/uploads/2013/10/QR-Code-Overview-150x150.jpeg" width="150"/></a><a class="wp_rp_title" href="https://coolshell.cn/articles/10590.html">二维码的生成细节和原理</a></li></ul></div></div>The post <a href="https://coolshell.cn/articles/7779.html">K-Means 算法</a> first appeared on <a href="https://coolshell.cn">酷 壳 - CoolShell</a>.</body></html>